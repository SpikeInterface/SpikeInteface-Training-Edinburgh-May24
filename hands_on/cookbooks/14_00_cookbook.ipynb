{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spikeinterface Cookbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spikeinterface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Recording and Sorting objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core import generate_recording \n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10])\n",
    "recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core import generate_sorting \n",
    "\n",
    "sorting = generate_sorting(num_units=3, durations=[10])\n",
    "sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting channel names and unit IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = recording.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])  # This is not in-place\n",
    "recording.get_channel_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = sorting.rename_units(new_unit_ids=[\"unit1\", \"unit2\", \"unit3\"])  # This is not in-place\n",
    "sorting.get_unit_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a Recording and Sorting Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_sliced_recording = recording.channel_slice(channel_ids=[\"a\", \"b\"])\n",
    "channel_sliced_recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_selected_sorting = sorting.select_units(unit_ids=[\"unit1\", \"unit2\"])\n",
    "unit_selected_sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames / Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_recording = recording.frame_slice(start_frame=0, end_frame=1000)\n",
    "sliced_recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_sorting = sorting.frame_slice(start_frame=0, end_frame=1000)\n",
    "sliced_sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating recordings (across time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core import concatenate_recordings\n",
    "\n",
    "recording1 = generate_recording(num_channels=3, durations=[10])\n",
    "recording2 = generate_recording(num_channels=3, durations=[10])\n",
    "\n",
    "concanted_recordings = concatenate_recordings([recording1, recording2])\n",
    "\n",
    "assert concanted_recordings.get_duration() == recording1.get_duration()  + recording2.get_duration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating channels to a single recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core import aggregate_channels\n",
    "\n",
    "recording1 = generate_recording(num_channels=3, durations=[10], set_probe=False)  # To avoid location check\n",
    "recording1 = recording1.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])\n",
    "recording2 = generate_recording(num_channels=2, durations=[10], set_probe=False)  \n",
    "recording2 = recording2.rename_channels(new_channel_ids=[\"d\", \"e\"])\n",
    "\n",
    "aggregated_recording = aggregate_channels([recording1, recording2])  \n",
    "assert aggregated_recording.get_num_channels() == 5\n",
    "assert list(aggregated_recording.get_channel_ids()) == ['a', 'b', 'c', 'd', 'e']  # Failing right now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of operations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![Recording Operations](./recording_operations.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we parallelize over\n",
    "\n",
    "![Chuking Description](./parallel_processing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to control paralell execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lenght of the chunk\n",
    "    * chunk_duration :  Lenght of the chunk in seconds\n",
    "    * chunk_size: Number of samples per chunk\n",
    "    * chunk_memory: Memory usage for each job (e.g. \"100M\", \"1G\")\n",
    "    * total_memory Total memory usage (e.g. \"500M\", \"2G\")\n",
    "* n_jobs: Number of jobs to use. With -1 the number of jobs is the same as number of cores\n",
    "* progress_bar: Whether to show a progress bar\n",
    "* mp_context: fork, span or forkserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![job_kwargs](./job_kwargs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting global job_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = generate_sorting(num_units=3, durations=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Recording and Sorting Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_recording\n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10], set_probe=True)\n",
    "recording = recording.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])  # This is not in-place\n",
    "recording.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "\n",
    "folder_path = Path(\"./test_recording\")\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "binary_recording = recording.save_to_folder(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "binary_recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_sorting\n",
    "\n",
    "sorting = generate_sorting(num_units=3, durations=[10])\n",
    "sorting = sorting.rename_units(new_unit_ids=[\"unit1\", \"unit2\", \"unit3\"])  # This is not in-place\n",
    "\n",
    "sorting.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "\n",
    "folder_path = Path(\"./test_sorting\")\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "binary_sorting = sorting.save_to_folder(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "binary_sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zarr format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_recording\n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10], set_probe=True)\n",
    "recording = recording.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])  # This is not in-place\n",
    "recording.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "folder_path = Path(\"./test_recording.zarr\")\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "zarr_recording = recording.save_to_zarr(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "zarr_recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_recording._root.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_sorting\n",
    "\n",
    "sorting = generate_sorting(num_units=3, durations=[10])\n",
    "sorting = sorting.rename_units(new_unit_ids=[\"unit1\", \"unit2\", \"unit3\"])  # This is not in-place\n",
    "\n",
    "sorting.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "\n",
    "folder_path = Path(\"./test_sorting.zarr\")\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "zarr_sorting = sorting.save_to_zarr(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "zarr_sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_sorting._root.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
