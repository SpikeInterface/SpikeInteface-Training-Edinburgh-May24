{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple sorter on generated dataset\n",
    "\n",
    "In this quick demp, we will simulate 5 minutes of a very simple dataset one a tetrode with 5 units only.\n",
    "\n",
    "We will run a very \"simple\" sorter on it, which mimics the \"old\" way of doing spike sorting.\n",
    "The simple sorter runs the following steps:\n",
    "  1. preprocess signal\n",
    "  2. detect peaks with a threshold\n",
    "  3. extract waveforms snippets\n",
    "  4. dimensionality reduction of waveforms using SVD (aka PCA)\n",
    "  5. try some clustering algorithms on the projected waveforms:\n",
    "     * HDBSCAN\n",
    "     * KMeans\n",
    "     * MeanShift\n",
    "     * ...\n",
    "\n",
    "This demo should demonstrate how easy it is to setup a simple spike sorting pipeline, **BUT* also the drawback and limits of this apprach without template matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for debuging\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spikeinterface.full as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path where we want to run the spike sorting\n",
    "base_folder = Path(\"/home/samuel/DataSpikeSorting/Edinburgh_SI_tutorials/generated_recording/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.set_global_job_kwargs(n_jobs=-1, progress_bar=True, chunk_duration=\"1s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "`spikeinterface` has a range of tools (from simple to more sophisticated) to generate \"fake\" datasets with ground-truth (aka known spiking activity) for testing purposes. \n",
    "\n",
    "Here, we simulated a simple recording of 5 minutes with 5 units on a tetrode (4 channels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.generate_drifting_recording?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording, drifting_recording, gt_sorting = si.generate_drifting_recording(\n",
    "    num_units=5,\n",
    "    duration=300.,\n",
    "    generate_probe_kwargs=dict(\n",
    "        num_columns=2,\n",
    "        num_contact_per_column=[2, 2],\n",
    "        xpitch=20,\n",
    "        ypitch=20,\n",
    "        contact_shapes=\"square\",\n",
    "        contact_shape_params={\"width\": 12},\n",
    "    ),\n",
    "    generate_templates_kwargs=dict(\n",
    "        ms_before=1.5,\n",
    "        ms_after=3.0,\n",
    "        mode=\"ellipsoid\",\n",
    "        unit_params=dict(\n",
    "            alpha=(150.0, 500.0),\n",
    "            spatial_decay=(10, 40),\n",
    "        ),\n",
    "    ),\n",
    "    generate_unit_locations_kwargs=dict(\n",
    "        margin_um=10.0,\n",
    "        minimum_z=6.0,\n",
    "        maximum_z=25.0,\n",
    "        minimum_distance=18.0,\n",
    "        max_iteration=100,\n",
    "        distance_strict=False,\n",
    "    ),    \n",
    "    generate_sorting_kwargs=dict(firing_rates=(2.0, 5.0), refractory_period_ms=4.0),\n",
    "    generate_noise_kwargs=dict(noise_levels=(12.0, 15.0), spatial_decay=25.0),\n",
    "    seed=2205\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_probe_map(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_traces(recording, backend=\"ephyviewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a sorter\n",
    "\n",
    "TODO schematics of this sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_folder = base_folder / \"static_simple_sorter\"\n",
    "if sorter_folder.exists():\n",
    "    shutil.rmtree(sorter_folder)\n",
    "\n",
    "sorter_params = dict(\n",
    "    apply_preprocessing=True,\n",
    "    # apply_preprocessing=False,\n",
    "    waveforms=dict(ms_before=1.0, ms_after=1.8),\n",
    "    filtering=dict(freq_min=300, freq_max=8000.0),\n",
    "    detection=dict(peak_sign=\"neg\", detect_threshold=5., exclude_sweep_ms=0.4, radius_um=100),\n",
    "    features=dict(n_components=3),\n",
    "    clustering=dict(method=\"hdbscan\"),\n",
    "    # clustering=dict(method=\"kmeans\", n_clusters=3),\n",
    "    # clustering=dict(method=\"gaussian_mixture\", n_components=5),\n",
    "    # clustering=dict(method=\"mean_shift\", bin_seeding=True),\n",
    "    # clustering=dict(method=\"affinity_propagation\"),\n",
    "    job_kwargs=dict(n_jobs=-1),\n",
    ")\n",
    "sorting = si.run_sorter(\"simple\", recording, output_folder=sorter_folder, verbose=True, **sorter_params)\n",
    "print(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore some waveforms \"features\"\n",
    "\n",
    "Our \"simple_sorter\" produces some output files we can explore after the `run_sorter(...)` function.\n",
    "\n",
    "The file `features_tsvd.npy` contains the features computed by our sorter.\n",
    "The file `peak_labels.npy` contains the labels set by our sorter.\n",
    "\n",
    "The shape of the `features_tsvd` is `(num_spikes, num_components, num_channels)`.\n",
    "These features can be flattened (make them a 1D array) and then visualized with tools like `UMAP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(sorter_folder / \"sorter_output/features/features_tsvd.npy\")\n",
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "\n",
    "peak_labels = np.load(sorter_folder / \"sorter_output/features/peak_labels.npy\")\n",
    "print(features.shape, features_flat.shape,  peak_labels.shape,features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "mapper = umap.UMAP().fit(features_flat)\n",
    "print(mapper)\n",
    "umap.plot.points(mapper, labels=peak_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `HDBSCAN` clustering method used by the \"simple sorter\" is in agreement with the `UMAP` dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SortingAnalyzer\n",
    "\n",
    "We can now construct a `SortingAnalyzer` using the `recording` and `sorting` objects and explore the results with the `spikeinterface-gui`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = si.create_sorting_analyzer(sorting, recording, sparse=False)\n",
    "analyzer.compute([\"random_spikes\", \"waveforms\", \"templates\", \"noise_levels\"])\n",
    "analyzer.compute([\"spike_amplitudes\", \"unit_locations\", \"principal_components\", \"correlograms\", \"template_similarity\"])\n",
    "analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"amplitude_cutoff\", \"rp_violation\"])\n",
    "analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(analyzer, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that 2 units should be merged!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SortingAnalyzer on the ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_analyzer = si.create_sorting_analyzer(gt_sorting, recording, sparse=False)\n",
    "gt_analyzer.compute([\"random_spikes\", \"waveforms\", \"templates\", \"noise_levels\"])\n",
    "gt_analyzer.compute([\"spike_amplitudes\", \"unit_locations\", \"principal_components\", \"correlograms\", \"template_similarity\"])\n",
    "gt_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"amplitude_cutoff\", \"rp_violation\"])\n",
    "gt_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_sorting_summary(gt_analyzer, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with ground truth\n",
    "\n",
    "`spikeinterface` has a simple way check the result of a sorter and benchmark it against the ground-truth sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = si.compare_sorter_to_ground_truth(gt_sorting, sorting)\n",
    "si.plot_agreement_matrix(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curation with quality metrics\n",
    "\n",
    "We can try to automatically \"clean\" the sorting results with quality metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = analyzer.get_extension(\"quality_metrics\").get_data()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = metrics.query(\"rp_contamination < 0.25 & snr > 7\")\n",
    "display(keep)\n",
    "\n",
    "keep_unit_ids = keep.index.values\n",
    "print(keep_unit_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_clean = analyzer.select_units(unit_ids=keep_unit_ids)\n",
    "analyzer_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(analyzer_clean, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare curated sorting with the ground truth\n",
    "\n",
    "Here we compare the cleaned sorting output against ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_clean = si.compare_sorter_to_ground_truth(gt_sorting, analyzer_clean.sorting)\n",
    "si.plot_agreement_matrix(comp_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More difficult: the drift!\n",
    "\n",
    "So far, we have analyzed a \"static\" recording. What happens when we add some drift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_drift_analyzer = si.create_sorting_analyzer(gt_sorting, drifting_recording, sparse=False)\n",
    "gt_drift_analyzer.compute([\"random_spikes\", \"waveforms\", \"templates\", \"noise_levels\"])\n",
    "gt_drift_analyzer.compute([\"spike_amplitudes\", \"unit_locations\", \"principal_components\", \"correlograms\", \"template_similarity\"])\n",
    "gt_drift_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"amplitude_cutoff\", \"rp_violation\"])\n",
    "gt_drift_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(gt_drift_analyzer, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_folder = base_folder / \"drifting_simple_sorter\"\n",
    "if sorter_folder.exists():\n",
    "    shutil.rmtree(sorter_folder)\n",
    "\n",
    "sorter_params = dict(\n",
    "    apply_preprocessing=True,\n",
    "    # apply_preprocessing=False,\n",
    "    waveforms=dict(ms_before=1.0, ms_after=1.8),\n",
    "    filtering=dict(freq_min=300, freq_max=8000.0),\n",
    "    detection=dict(peak_sign=\"neg\", detect_threshold=5., exclude_sweep_ms=0.4, radius_um=100),\n",
    "    features=dict(n_components=3),\n",
    "    clustering=dict(method=\"hdbscan\"),\n",
    "    # clustering=dict(method=\"kmeans\", n_clusters=3),\n",
    "    # clustering=dict(method=\"gaussian_mixture\", n_components=5),\n",
    "    # clustering=dict(method=\"mean_shift\", bin_seeding=True),\n",
    "    # clustering=dict(method=\"affinity_propagation\"),\n",
    "    job_kwargs=dict(n_jobs=-1),\n",
    ")\n",
    "sorting_drift = si.run_sorter(\"simple\", drifting_recording, output_folder=sorter_folder, verbose=True, **sorter_params)\n",
    "print(sorting_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_analyzer = si.create_sorting_analyzer(sorting_drift, drifting_recording, sparse=False)\n",
    "drift_analyzer.compute([\"random_spikes\", \"waveforms\", \"templates\", \"noise_levels\"])\n",
    "drift_analyzer.compute([\"spike_amplitudes\", \"unit_locations\", \"principal_components\", \"correlograms\", \"template_similarity\"])\n",
    "drift_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"amplitude_cutoff\", \"rp_violation\"])\n",
    "drift_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(drift_analyzer, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_drift = si.compare_sorter_to_ground_truth(gt_sorting, sorting_drift)\n",
    "si.plot_agreement_matrix(comp_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drift makes things much more complicated! For long probes, like Neuropixels and other silicon probes, several drift correction methods can be applied as a preprocessing step to improve spike sorting performance.\n",
    "\n",
    "\n",
    "To conclude, even for simple cases spike sorting can be tricky! In the next tutorial, we will see an overview application of `spikeinterface` on a real-world example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
